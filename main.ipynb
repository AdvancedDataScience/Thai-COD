{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THai AI - Cause of Dead(THAI-COD)\n",
    "##### For THAIBOD\n",
    "##### By Dr. Thanawat Wongphan\n",
    "##### V. 1.0 Indy Code name\n",
    "##### V. 1.1 Trat version, Real data with cleaning\n",
    "##### Contact: thwong@iu.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=orange>Section I: Introduction</font>\n",
    "This program is an innovation which has been well designed for predict best suitable cause of dead(COD) by using multiple reasons from hospital summary. Using the training set from 2020 research from Thai BOD. This program has been designed by python infrastructure with AI abilities from tensorflow opensource. This program will compare multiple AI-models and return which types of model should be selected in Thailand setting.\n",
    "\n",
    "#### This programs consisting of six sections:\n",
    "* Section I:    <tab>Introduction</tab>\n",
    "* Section II:   <tab>library and functions load</tab>\n",
    "* Section III:   <tab>Data manipulation</tab>\n",
    "* Section IV:  AI process\n",
    "* Section V:   Analysis\n",
    "* Section VI:    Conclusion and discussion\n",
    "\n",
    "<b>This jupyter notebook can be used and tested by open communities under the GPL-licensed by Dr.Thanawat Wongphan and THAI-BOD working group.</b>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=orange>Section II: Library and functions load</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Section II:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, LSTM, Activation, Conv1D,MaxPooling1D,Flatten,GlobalAveragePooling1D,GlobalMaxPooling1D\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras import layers\n",
    "from keras.layers import Flatten\n",
    "from keras import backend as K\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler,LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error,accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Tree Visualisation\n",
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import Image\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=orange>Section III: Data manipulation</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Data loading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: Data/SampleData.xlsx has 40 columns and 6162 rows. The sample of first three rows are:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qcode</th>\n",
       "      <th>Province</th>\n",
       "      <th>Province_name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>lccaattmm</th>\n",
       "      <th>dyear</th>\n",
       "      <th>dmon</th>\n",
       "      <th>ddate</th>\n",
       "      <th>ghos_name</th>\n",
       "      <th>...</th>\n",
       "      <th>P_a_Final_New</th>\n",
       "      <th>P_a_ICD10_Final_New</th>\n",
       "      <th>P_b_Final_New</th>\n",
       "      <th>P_b_ICD10_Final_New</th>\n",
       "      <th>P_c_Final_New</th>\n",
       "      <th>P_c_ICD10_Final_new</th>\n",
       "      <th>P_d_Final_New</th>\n",
       "      <th>P_d_ICD10_Final_New</th>\n",
       "      <th>P_e_Final_New</th>\n",
       "      <th>P_e_ICD10_Final_New</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1102010011</td>\n",
       "      <td>10</td>\n",
       "      <td>BKK</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10200400</td>\n",
       "      <td>2561</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>IN</td>\n",
       "      <td>...</td>\n",
       "      <td>HYDRANENCEPHALY WITH SEVERE HYDROCEL WITH RDS</td>\n",
       "      <td>Q043,P835</td>\n",
       "      <td>PRETERM</td>\n",
       "      <td>-</td>\n",
       "      <td>TEENAGE PREGNANCY</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1102010021</td>\n",
       "      <td>10</td>\n",
       "      <td>BKK</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10200400</td>\n",
       "      <td>2561</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>IN</td>\n",
       "      <td>...</td>\n",
       "      <td>CONGENITAL HEART DIS. (PULMONARY VALVE ATRESIA...</td>\n",
       "      <td>Q220,Q250,P008,P832</td>\n",
       "      <td>RDS WITH VVLBE, PRETERM</td>\n",
       "      <td>P220</td>\n",
       "      <td>MATERNAL GDMA</td>\n",
       "      <td>O244</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1102010031</td>\n",
       "      <td>10</td>\n",
       "      <td>BKK</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>10200400</td>\n",
       "      <td>2561</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>IN</td>\n",
       "      <td>...</td>\n",
       "      <td>CONGENITAL HYPOPLASIA LEFT HEART SYNDROME(ASD ...</td>\n",
       "      <td>Q234,Q211</td>\n",
       "      <td>LBW</td>\n",
       "      <td>P070</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        qcode  Province Province_name  sex  age  lccaattmm  dyear  dmon  \\\n",
       "0  1102010011        10           BKK    1    0   10200400   2561    12   \n",
       "1  1102010021        10           BKK    1    0   10200400   2561    12   \n",
       "2  1102010031        10           BKK    2    0   10200400   2561    12   \n",
       "\n",
       "   ddate ghos_name  ...                                      P_a_Final_New  \\\n",
       "0     24        IN  ...      HYDRANENCEPHALY WITH SEVERE HYDROCEL WITH RDS   \n",
       "1      9        IN  ...  CONGENITAL HEART DIS. (PULMONARY VALVE ATRESIA...   \n",
       "2      3        IN  ...  CONGENITAL HYPOPLASIA LEFT HEART SYNDROME(ASD ...   \n",
       "\n",
       "   P_a_ICD10_Final_New            P_b_Final_New P_b_ICD10_Final_New  \\\n",
       "0            Q043,P835                  PRETERM                   -   \n",
       "1  Q220,Q250,P008,P832  RDS WITH VVLBE, PRETERM                P220   \n",
       "2            Q234,Q211                      LBW                P070   \n",
       "\n",
       "       P_c_Final_New P_c_ICD10_Final_new P_d_Final_New P_d_ICD10_Final_New  \\\n",
       "0  TEENAGE PREGNANCY                 NaN                               NaN   \n",
       "1     MATERNAL GDMA                 O244                               NaN   \n",
       "2                                    NaN                               NaN   \n",
       "\n",
       "  P_e_Final_New P_e_ICD10_Final_New  \n",
       "0                               NaN  \n",
       "1                               NaN  \n",
       "2                               NaN  \n",
       "\n",
       "[3 rows x 40 columns]"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flname=\"Data/SampleData.xlsx\"\n",
    "OriginalCSV = pd.read_excel(flname)\n",
    "print(\"File: {} has {} columns and {} rows. The sample of first three rows are:\".format(flname,OriginalCSV.shape[1],OriginalCSV.shape[0]))\n",
    "OriginalCSV.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Data cleaning and text labels encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "CleanData=OriginalCSV\n",
    "labels_ICDs = LabelEncoder()\n",
    "Corpus =    list(set(list(CleanData['Final_dx_New_ICD10']))) + list(set(list(CleanData['a_ICD10_Final_New']))) + list(set(list(CleanData['b_ICD10_Final_New']))) + list(set(list(CleanData['c_ICD10_Final_New']))) + list(set(list(CleanData['d_ICD10_Final_New']))) \n",
    "labels_ICDs.fit(Corpus)\n",
    "CleanData['a_ICD10_Enc']=labels_ICDs.transform(CleanData['a_ICD10_Final_New'].values.ravel())\n",
    "CleanData['b_ICD10_Enc']=labels_ICDs.transform(CleanData['b_ICD10_Final_New'].values.ravel())\n",
    "CleanData['c_ICD10_Enc']=labels_ICDs.transform(CleanData['c_ICD10_Final_New'].values.ravel())\n",
    "CleanData['d_ICD10_Enc']=labels_ICDs.transform(CleanData['d_ICD10_Final_New'].values.ravel())\n",
    "CleanData['Final_dx_Enc']=labels_ICDs.transform(CleanData['Final_dx_New_ICD10'].values.ravel())\n",
    "ConversionTable=pd.read_excel(\"Data/All_Units_Conversion.xlsx\")\n",
    "def TimeStandardize(tmp):\n",
    "    if (isinstance(tmp, str)):\n",
    "        if((tmp.find(\" \")>-1) & (tmp.find(\",\")==-1) & (tmp.find(\"-\")==-1) & (tmp.find(\"last\")==-1) ):\n",
    "            t=tmp.split(\" \")\n",
    "            t[0]=t[0].replace(\"+\",'')\n",
    "            t[0]=t[0].replace(\"ๅ\",'')\n",
    "            t[0]=t[0].replace(\"<\",'')\n",
    "            t[0]=t[0].replace(\"At\",'')\n",
    "            t[0]=t[0].replace(\"?\",'')\n",
    "            if((t[0]=='') | ((t[0]=='.'))):\n",
    "                return np.nan\n",
    "            else:\n",
    "                try:\n",
    "                    V1=ConversionTable[ConversionTable['Unit']==t[1]]['Value'].iloc[0]\n",
    "                    V0=float(t[0])\n",
    "                    MultiplyResult = V0*V1\n",
    "                    return MultiplyResult\n",
    "                except:\n",
    "                    return np.nan\n",
    "        else:\n",
    "            return np.nan\n",
    "    else:\n",
    "        return np.nan\n",
    "CleanData['a_time_standard']=CleanData['a_time_Final_New'].apply(TimeStandardize)\n",
    "CleanData['b_time_standard']=CleanData['b_time_Final_New'].apply(TimeStandardize)\n",
    "CleanData['c_time_standard']=CleanData['c_time_Final_New'].apply(TimeStandardize)\n",
    "CleanData['d_time_standard']=CleanData['d_time_Final_New'].apply(TimeStandardize)\n",
    "CleanData.dropna(subset=['a_time_standard', 'b_time_standard','c_time_standard','d_time_standard'])\n",
    "CleanData['place']=CleanData['ghos_name'].apply(lambda x: 1 if x=='IN' else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 Data shuffle and partitioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3.1 Sizing partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From total 6,162 rows, the samples have been partitioned into 3 sets: Train/Dev/Test size: 4930/616/616\n"
     ]
    }
   ],
   "source": [
    "#Declare ratio of Train/Dev and the rest is test set\n",
    "TrainRatio=0.8\n",
    "DevRatio=0.1\n",
    "TrainSize=int(np.round(TrainRatio*CleanData.shape[0]))\n",
    "DevSize=int(np.round(DevRatio*CleanData.shape[0]))\n",
    "TestSize=CleanData.shape[0]-TrainSize-DevSize\n",
    "print(\"From total {:,} rows, the samples have been partitioned into 3 sets: Train/Dev/Test size: {}/{}/{}\".format(\n",
    "    CleanData.shape[0],TrainSize,DevSize,TestSize\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3.2 Shuffle index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind=CleanData.index\n",
    "ind_list=ind.to_list()\n",
    "np.random.shuffle(ind_list)\n",
    "ind_shuffle_list=ind_list\n",
    "TrainIndex=ind_shuffle_list[0:TrainSize]\n",
    "DevIndex=ind_shuffle_list[TrainSize:(TrainSize+DevSize)]\n",
    "TestIndex=ind_shuffle_list[(TrainSize+DevSize):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3.3 partition data by index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainSet=CleanData.iloc[TrainIndex]\n",
    "DevSet=CleanData.iloc[DevIndex]\n",
    "TestSet=CleanData.iloc[TestIndex]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=orange>Section IV: AI</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.0 Random Forest Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['qcode', 'Province', 'Province_name', 'sex', 'age', 'lccaattmm',\n",
       "       'dyear', 'dmon', 'ddate', 'ghos_name', 'dcause_1', 'ncause',\n",
       "       'agreement_New', 'Final_dx_New', 'Final_dx_New_ICD10', 'a_Final_new',\n",
       "       'a_ICD10_Final_New', 'a_time_Final_New', 'b_Final_New',\n",
       "       'b_ICD10_Final_New', 'b_time_Final_New', 'c_Final_New',\n",
       "       'c_ICD10_Final_New', 'c_time_Final_New', 'd_Final_New',\n",
       "       'd_ICD10_Final_New', 'd_time_Final_New', 'II_Final_New',\n",
       "       'II_time_Final_New', 'Rules apply_Final_New', 'P_a_Final_New',\n",
       "       'P_a_ICD10_Final_New', 'P_b_Final_New', 'P_b_ICD10_Final_New',\n",
       "       'P_c_Final_New', 'P_c_ICD10_Final_new', 'P_d_Final_New',\n",
       "       'P_d_ICD10_Final_New', 'P_e_Final_New', 'P_e_ICD10_Final_New',\n",
       "       'a_ICD10_Enc', 'b_ICD10_Enc', 'c_ICD10_Enc', 'd_ICD10_Enc',\n",
       "       'Final_dx_Enc', 'a_time_standard', 'b_time_standard', 'c_time_standard',\n",
       "       'd_time_standard', 'place'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainSet.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"xSelectedFeatures = ['Province',  'sex', 'age',\\n       'a_ICD10_Enc',  \\n       'b_ICD10_Enc', \\n       'c_ICD10_Enc', \\n       'd_ICD10_Enc']\""
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AllColumns = ['qcode', 'Province', 'Province_name', 'sex', 'age', 'lccaattmm',\n",
    "       'dyear', 'dmon', 'ddate', 'ghos_name', 'dcause_1', 'ncause',\n",
    "       'agreement_New', 'Final_dx_New', 'Final_dx_New_ICD10', 'a_Final_new',\n",
    "       'a_ICD10_Final_New', 'a_time_Final_New', 'b_Final_New',\n",
    "       'b_ICD10_Final_New', 'b_time_Final_New', 'c_Final_New',\n",
    "       'c_ICD10_Final_New', 'c_time_Final_New', 'd_Final_New',\n",
    "       'd_ICD10_Final_New', 'd_time_Final_New', 'II_Final_New',\n",
    "       'II_time_Final_New', 'Rules apply_Final_New', 'P_a_Final_New',\n",
    "       'P_a_ICD10_Final_New', 'P_b_Final_New', 'P_b_ICD10_Final_New',\n",
    "       'P_c_Final_New', 'P_c_ICD10_Final_new', 'P_d_Final_New',\n",
    "       'P_d_ICD10_Final_New', 'P_e_Final_New', 'P_e_ICD10_Final_New',\n",
    "       'a_ICD10_Enc', 'b_ICD10_Enc', 'd_ICD10_Enc', 'Final_dx_Enc',\n",
    "       'c_ICD10_Enc', 'NEwCol', 'a_time_standard', 'b_time_standard',\n",
    "       'c_time_standard', 'd_time_standard', 'place']\n",
    "ySelectedFeatures = ['Final_dx_Enc']\n",
    "xSelectedFeatures = ['Province',  'sex', 'age','place',\n",
    "       'a_ICD10_Enc', 'a_time_standard', \n",
    "       'b_ICD10_Enc', 'b_time_standard', \n",
    "       'c_ICD10_Enc', 'c_time_standard',\n",
    "       'd_ICD10_Enc', 'd_time_standard']\n",
    "\"\"\"xSelectedFeatures = ['Province',  'sex', 'age',\n",
    "       'a_ICD10_Enc',  \n",
    "       'b_ICD10_Enc', \n",
    "       'c_ICD10_Enc', \n",
    "       'd_ICD10_Enc']\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thanawat/anaconda3/envs/spyder/lib/python3.11/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY OF THE MODEL: 0.43993506493506496\n"
     ]
    }
   ],
   "source": [
    "\n",
    "TrainSet = TrainSet.fillna(0)\n",
    "DevSet = DevSet.fillna(0)\n",
    "x_Train=TrainSet[xSelectedFeatures]\n",
    "y_Train=TrainSet[ySelectedFeatures]\n",
    "x_Dev=DevSet[xSelectedFeatures]\n",
    "y_Dev=DevSet[ySelectedFeatures]\n",
    "clf = RandomForestClassifier(n_estimators = 100)\n",
    "clf.fit(x_Train, y_Train)\n",
    "# performing predictions on the test dataset\n",
    "y_pred = clf.predict(x_Dev)\n",
    "AccModel=metrics.accuracy_score(y_pred, y_Dev)\n",
    "print(\"ACCURACY OF THE MODEL:\", AccModel)\n",
    "BestAccuracy={'Model':['Randomforest'],'Accuracy':AccModel}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1 CNN Deep learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_3 (Conv1D)           (None, 2, 10)             120       \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 2, 10)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 20)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 500)               10500     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 714)               357714    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 368,334\n",
      "Trainable params: 368,334\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 33.7629 - accuracy: 0.0189\n",
      "Epoch 2/10\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 237.5945 - accuracy: 0.0099\n",
      "Epoch 3/10\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 951.0677 - accuracy: 0.0059\n",
      "Epoch 4/10\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 2220.8330 - accuracy: 0.0063\n",
      "Epoch 5/10\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 5381.5742 - accuracy: 0.0069\n",
      "Epoch 6/10\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 10063.3320 - accuracy: 0.0063\n",
      "Epoch 7/10\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 16637.6289 - accuracy: 0.0049\n",
      "Epoch 8/10\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 26048.9082 - accuracy: 0.0065\n",
      "Epoch 9/10\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 41486.4180 - accuracy: 0.0067\n",
      "Epoch 10/10\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 63796.8438 - accuracy: 0.0069\n",
      "155/155 [==============================] - 0s 719us/step\n"
     ]
    }
   ],
   "source": [
    "#Use Class at 5 min: 0 = neutral, 1 = sell, 2= buy ,3 = both sell and buy correct\n",
    "\n",
    "x_Train=TrainSet[xSelectedFeatures]\n",
    "y_Train_pre_HOT = TrainSet[ySelectedFeatures]\n",
    "y_Train= tf.one_hot(np.reshape(y_Train_pre_HOT,x_Train.shape[0]),y_Train_pre_HOT[ySelectedFeatures[0]].nunique())\n",
    "y_Dev = DevSet[ySelectedFeatures]\n",
    "y_Test = TestSet[ySelectedFeatures][:TestSize]\n",
    "y_Train_pre_HOT.value_counts()\n",
    "filtered_train = np.reshape(x_Train,(x_Train.shape[0],x_Train.shape[1],1))\n",
    "EpochNum=10\n",
    "filtersize=10\n",
    "model_cnn_wide_10 = Sequential()\n",
    "model_cnn_wide_10.add(Conv1D(filters=filtersize, kernel_size=filtered_train.shape[1]-1, input_shape=(filtered_train.shape[1], filtered_train.shape[2])))\n",
    "model_cnn_wide_10.add(MaxPooling1D(pool_size=1 ))\n",
    "model_cnn_wide_10.add(Flatten())\n",
    "model_cnn_wide_10.add(Dense(500, activation='relu'))\n",
    "model_cnn_wide_10.add(Dense(y_Train_pre_HOT[ySelectedFeatures[0]].nunique(), activation='softmax'))\n",
    "model_cnn_wide_10.compile(loss='CategoricalCrossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_cnn_wide_10.summary()\n",
    "history_cnn_wide_10=model_cnn_wide_10.fit(x=filtered_train, y=y_Train, epochs=EpochNum)\n",
    "yhat_cnn_wide_10 = model_cnn_wide_10.predict(filtered_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best accuracy of CNN is 0.690%\n"
     ]
    }
   ],
   "source": [
    "#Based on train data:\n",
    "print(\"The best accuracy of CNN is {:.3%}\".format(history_cnn_wide_10.history['accuracy'][-1]))\n",
    "BestAccuracy={'Model':['RandomForest','CNN'],'Accuracy':[AccModel,history_cnn_wide_10.history['accuracy'][-1]]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=orange>Section V: Analysis</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.1 Analysis of accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Number</th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.439935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.006897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model Number    Model Name  Accuracy\n",
       "0             1  RandomForest  0.439935\n",
       "1             2           CNN  0.006897"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "AccuracyTable = pd.DataFrame({'Model Number':[1,2],\n",
    "                              'Model Name':[BestAccuracy['Model'][0],BestAccuracy['Model'][1]],\n",
    "                              'Accuracy':[BestAccuracy['Accuracy'][0],BestAccuracy['Accuracy'][1]]})\n",
    "display(AccuracyTable )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=orange>Section VI: Conclusion and discussion</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      As you see, the predictive accuracy from model Random Forest is much higher than CNN but too far from truth.\n",
      "      Therefore we have to improve model by alpha engineering and model developing.\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "      As you see, the predictive accuracy from model Random Forest is much higher than CNN but too far from truth.\n",
    "      Therefore we have to improve model by alpha engineering and model developing.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spyder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
